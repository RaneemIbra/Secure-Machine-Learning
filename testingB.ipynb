{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Accuracy Results (Absolute Differences) ===\n",
      "Euclidean: avg=7.261438e-07, std=1.368150e-08, max=7.614550e-07\n",
      "Cosine: avg=2.957902e-09, std=8.402525e-10, max=4.819929e-09\n",
      "\n",
      "=== Runtime Results (seconds) ===\n",
      "Generation: avg=0.0000s, std=0.0001s, max=0.0010s\n",
      "Encryption: avg=0.0091s, std=0.0005s, max=0.0110s\n",
      "Computation: avg=0.0710s, std=0.0040s, max=0.0933s\n",
      "Decryption: avg=0.0000s, std=0.0002s, max=0.0015s\n",
      "\n",
      "=== Final Demo ===\n",
      "Euclidean distance (encrypted) = 9.206356 vs. cleartext = 9.206355\n",
      "Cosine similarity (encrypted) = 0.750358 vs. cleartext = 0.750358\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import statistics\n",
    "import numpy as np\n",
    "\n",
    "# -------------------------------\n",
    "# 1. Install & Import TenSEAL\n",
    "# -------------------------------\n",
    "#  pip install tenseal==0.9.0  (for example)\n",
    "#  or see https://github.com/OpenMined/TenSEAL\n",
    "import tenseal as ts\n",
    "\n",
    "# -------------------------------\n",
    "# Parameters (matching Part A)\n",
    "# -------------------------------\n",
    "# Suppose in Part A your embedding dimension was 512:\n",
    "VECTOR_DIM = 512   \n",
    "# If you truncated to 4 decimal places in Part A, \n",
    "# you can incorporate that in your random data generation if desired.\n",
    "\n",
    "# Number of times to repeat steps 1–4 for performance metrics\n",
    "REPETITIONS = 100\n",
    "\n",
    "# -------------------------------\n",
    "# 2. Create CKKS Context & Keys\n",
    "# -------------------------------\n",
    "# CKKS (HEaaN) scheme is used for approximate arithmetic on floating-point\n",
    "# data. We configure poly_modulus_degree and coeff_mod_bit_sizes (the modulus\n",
    "# chain) to balance performance, noise budget, and precision.\n",
    "#\n",
    "# Below is a common test configuration. For large-scale real usage, you may\n",
    "# need bigger parameters.\n",
    "context = ts.context(\n",
    "    ts.SCHEME_TYPE.CKKS,\n",
    "    poly_modulus_degree=8192,              # or 16384 for more complex operations\n",
    "    coeff_mod_bit_sizes=[60, 40, 40, 60]   # Typical \"default\" chain\n",
    ")\n",
    "context.generate_galois_keys()  # Needed for .sum() or vector rotations\n",
    "# Optional (but often recommended) if you do repeated multiplications:\n",
    "# context.generate_relin_keys()\n",
    "\n",
    "# Set the global scale (precision). This is a trade-off between numerical\n",
    "# accuracy and available noise budget.\n",
    "context.global_scale = 2 ** 40\n",
    "\n",
    "# -------------------------------\n",
    "# 3. Define Homomorphic Operations\n",
    "# -------------------------------\n",
    "# (Euclidean distance & Cosine similarity)\n",
    "# We'll show them as separate functions. We return the *decrypted* final\n",
    "# scalar so that we can compare to the cleartext. If you want to keep it\n",
    "# fully encrypted, just return the encrypted ciphertext.\n",
    "\n",
    "def homomorphic_euclidean_distance(enc_vec1, enc_vec2):\n",
    "    \"\"\"\n",
    "    Homomorphically computes Euclidean distance between enc_vec1 and enc_vec2:\n",
    "        dist = sqrt(sum( (vec1 - vec2)^2 ))\n",
    "    Returns the final scalar as float (decrypted).\n",
    "    \"\"\"\n",
    "    diff = enc_vec1 - enc_vec2               # ciphertext of (vec1 - vec2)\n",
    "    squared_diff = diff * diff               # ciphertext of (vec1 - vec2)^2\n",
    "    sum_squared_diff = squared_diff.sum()    # ciphertext of sum( (vec1 - vec2)^2 )\n",
    "    decrypted_sum = sum_squared_diff.decrypt()[0]  # single float in slot 0\n",
    "    return np.sqrt(decrypted_sum)\n",
    "\n",
    "def homomorphic_cosine_similarity(enc_vec1, enc_vec2):\n",
    "    \"\"\"\n",
    "    Homomorphically computes Cosine similarity between enc_vec1 and enc_vec2:\n",
    "        cos_sim = (vec1 · vec2) / (||vec1|| * ||vec2||)\n",
    "    Returns the final scalar as float (decrypted).\n",
    "    \"\"\"\n",
    "    dot_product = (enc_vec1 * enc_vec2).sum()  # ciphertext of dot(vec1, vec2)\n",
    "    norm1 = (enc_vec1 * enc_vec1).sum()        # ciphertext of dot(vec1, vec1)\n",
    "    norm2 = (enc_vec2 * enc_vec2).sum()        # ciphertext of dot(vec2, vec2)\n",
    "\n",
    "    # Decrypt intermediate results\n",
    "    decrypted_dot = dot_product.decrypt()[0]\n",
    "    decrypted_norm1 = norm1.decrypt()[0]\n",
    "    decrypted_norm2 = norm2.decrypt()[0]\n",
    "\n",
    "    return decrypted_dot / (np.sqrt(decrypted_norm1) * np.sqrt(decrypted_norm2))\n",
    "\n",
    "# -------------------------------\n",
    "# 4. Repeat Steps 1–4 & Measure Performance\n",
    "# -------------------------------\n",
    "accuracy_results = {\"Euclidean\": [], \"Cosine\": []}\n",
    "\n",
    "# We'll track runtime of each step:\n",
    "# (1) Vector Generation, (2) Encryption, (3) Encrypted Computation, (4) Decryption / Comparison\n",
    "runtime_results = {\n",
    "    \"Generation\": [],\n",
    "    \"Encryption\": [],\n",
    "    \"Computation\": [],\n",
    "    \"Decryption\": []   # For clarity, though we decrypt in-line in the functions above\n",
    "}\n",
    "\n",
    "for _ in range(REPETITIONS):\n",
    "    # Step 1: Generate two random vectors\n",
    "    t0 = time.time()\n",
    "    vector1 = np.random.uniform(0.0, 1.0, size=VECTOR_DIM)\n",
    "    vector2 = np.random.uniform(0.0, 1.0, size=VECTOR_DIM)\n",
    "    runtime_results[\"Generation\"].append(time.time() - t0)\n",
    "\n",
    "    # Step 2: Encrypt the vectors\n",
    "    t0 = time.time()\n",
    "    enc_vec1 = ts.ckks_vector(context, vector1)\n",
    "    enc_vec2 = ts.ckks_vector(context, vector2)\n",
    "    runtime_results[\"Encryption\"].append(time.time() - t0)\n",
    "\n",
    "    # Step 3: Homomorphically compute the similarity scores\n",
    "    t0 = time.time()\n",
    "    # (A) Euclidean Distance\n",
    "    encrypted_euclidean = homomorphic_euclidean_distance(enc_vec1, enc_vec2)\n",
    "    # (B) Cosine Similarity\n",
    "    encrypted_cosine = homomorphic_cosine_similarity(enc_vec1, enc_vec2)\n",
    "    runtime_results[\"Computation\"].append(time.time() - t0)\n",
    "\n",
    "    # Step 4: Decrypt and measure accuracy\n",
    "    # (We partly do decrypt inside the functions above, but let's still track time.)\n",
    "    t0 = time.time()\n",
    "    cleartext_euclidean = np.linalg.norm(vector1 - vector2)\n",
    "    cleartext_cosine = np.dot(vector1, vector2) / (\n",
    "        np.linalg.norm(vector1) * np.linalg.norm(vector2)\n",
    "    )\n",
    "    # Compare encrypted vs. cleartext\n",
    "    accuracy_results[\"Euclidean\"].append(abs(encrypted_euclidean - cleartext_euclidean))\n",
    "    accuracy_results[\"Cosine\"].append(abs(encrypted_cosine - cleartext_cosine))\n",
    "    runtime_results[\"Decryption\"].append(time.time() - t0)\n",
    "\n",
    "# -------------------------------\n",
    "# Print Summary of Accuracy Stats\n",
    "# -------------------------------\n",
    "import math\n",
    "import statistics\n",
    "\n",
    "print(\"\\n=== Accuracy Results (Absolute Differences) ===\")\n",
    "for metric, values in accuracy_results.items():\n",
    "    avg_diff = statistics.mean(values)\n",
    "    std_diff = statistics.pstdev(values) if len(values) > 1 else 0.0\n",
    "    max_diff = max(values)\n",
    "    print(f\"{metric}: avg={avg_diff:.6e}, std={std_diff:.6e}, max={max_diff:.6e}\")\n",
    "\n",
    "# -------------------------------\n",
    "# Print Summary of Runtime Stats\n",
    "# -------------------------------\n",
    "print(\"\\n=== Runtime Results (seconds) ===\")\n",
    "for step, times in runtime_results.items():\n",
    "    avg_t = statistics.mean(times)\n",
    "    std_t = statistics.pstdev(times) if len(times) > 1 else 0.0\n",
    "    max_t = max(times)\n",
    "    print(f\"{step}: avg={avg_t:.4f}s, std={std_t:.4f}s, max={max_t:.4f}s\")\n",
    "\n",
    "# -------------------------------\n",
    "# (Optional) Demonstration of final \"cleartext vs. encrypted\" check\n",
    "# -------------------------------\n",
    "print(\"\\n=== Final Demo ===\")\n",
    "demo_vec1 = np.random.uniform(0.0, 1.0, size=VECTOR_DIM)\n",
    "demo_vec2 = np.random.uniform(0.0, 1.0, size=VECTOR_DIM)\n",
    "ct_demo_vec1 = ts.ckks_vector(context, demo_vec1)\n",
    "ct_demo_vec2 = ts.ckks_vector(context, demo_vec2)\n",
    "\n",
    "# Encrypted computations\n",
    "encrypted_euc_demo = homomorphic_euclidean_distance(ct_demo_vec1, ct_demo_vec2)\n",
    "encrypted_cos_demo = homomorphic_cosine_similarity(ct_demo_vec1, ct_demo_vec2)\n",
    "\n",
    "# Cleartext computations\n",
    "clear_euc_demo = np.linalg.norm(demo_vec1 - demo_vec2)\n",
    "clear_cos_demo = np.dot(demo_vec1, demo_vec2) / (\n",
    "    np.linalg.norm(demo_vec1) * np.linalg.norm(demo_vec2)\n",
    ")\n",
    "\n",
    "print(f\"Euclidean distance (encrypted) = {encrypted_euc_demo:.6f} vs. cleartext = {clear_euc_demo:.6f}\")\n",
    "print(f\"Cosine similarity (encrypted) = {encrypted_cos_demo:.6f} vs. cleartext = {clear_cos_demo:.6f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
