{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 85.82% with Threshold: 0.43999999999999984\n",
      "Test Accuracy: 88.20% with Threshold: 0.45999999999999985\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras_vggface.vggface import VGGFace\n",
    "from keras_vggface.utils import preprocess_input\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import normalize\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Enable GPU memory growth\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(\"Error enabling GPU memory growth:\", e)\n",
    "\n",
    "# Paths\n",
    "base_dir = os.path.join('dataset', 'lfw-deepfunneled', 'lfw-deepfunneled')\n",
    "pairs_train_path = 'pairsDevTrain.txt'\n",
    "pairs_test_path = 'pairsDevTest.txt'\n",
    "\n",
    "# Normalize file and directory names for compatibility\n",
    "def normalize_name(name):\n",
    "    return name.replace(' ', '_')\n",
    "\n",
    "# Function to load pairs from the LFW pairs file\n",
    "def load_pairs(pairs_path, base_dir):\n",
    "    pairs = []\n",
    "    with open(pairs_path, 'r') as f:\n",
    "        for line in f.readlines()[1:]:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) == 3:  # Positive pair\n",
    "                person, img1, img2 = parts\n",
    "                person = normalize_name(person)\n",
    "                img1_path = os.path.join(base_dir, person, f\"{person}_{int(img1):04d}.jpg\")\n",
    "                img2_path = os.path.join(base_dir, person, f\"{person}_{int(img2):04d}.jpg\")\n",
    "                if os.path.exists(img1_path) and os.path.exists(img2_path):\n",
    "                    pairs.append((img1_path, img2_path, 1))\n",
    "            elif len(parts) == 4:  # Negative pair\n",
    "                person1, img1, person2, img2 = parts\n",
    "                person1, person2 = normalize_name(person1), normalize_name(person2)\n",
    "                img1_path = os.path.join(base_dir, person1, f\"{person1}_{int(img1):04d}.jpg\")\n",
    "                img2_path = os.path.join(base_dir, person2, f\"{person2}_{int(img2):04d}.jpg\")\n",
    "                if os.path.exists(img1_path) and os.path.exists(img2_path):\n",
    "                    pairs.append((img1_path, img2_path, 0))\n",
    "    return pairs\n",
    "\n",
    "# Load pairs\n",
    "train_pairs = load_pairs(pairs_train_path, base_dir)\n",
    "test_pairs = load_pairs(pairs_test_path, base_dir)\n",
    "\n",
    "# Load VGGFace model for embeddings (ResNet50 backbone)\n",
    "image_input = Input(shape=(224, 224, 3))\n",
    "vggface_model = VGGFace(model='resnet50', input_tensor=image_input, include_top=False, pooling='avg')\n",
    "embedding_model = Model(inputs=vggface_model.input, outputs=vggface_model.output)\n",
    "\n",
    "# Fine-tune the model\n",
    "for layer in vggface_model.layers[:-5]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Function to preprocess and augment images\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    brightness_range=[0.8, 1.2],\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "def preprocess_image(img_path, augment=False):\n",
    "    img = tf.keras.preprocessing.image.load_img(img_path, target_size=(224, 224))\n",
    "    img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    img_array = preprocess_input(img_array, version=1)\n",
    "    if augment:\n",
    "        img_array = datagen.random_transform(img_array)\n",
    "    return img_array\n",
    "\n",
    "# Function to generate embeddings\n",
    "def generate_embeddings(pairs, model, augment=False):\n",
    "    embeddings = []\n",
    "    labels = []\n",
    "    for img1_path, img2_path, label in pairs:\n",
    "        try:\n",
    "            img1 = preprocess_image(img1_path, augment=augment)\n",
    "            img2 = preprocess_image(img2_path, augment=augment)\n",
    "            emb1 = model.predict(np.expand_dims(img1, axis=0), verbose=0)[0]\n",
    "            emb2 = model.predict(np.expand_dims(img2, axis=0), verbose=0)[0]\n",
    "            embeddings.append((emb1, emb2))\n",
    "            labels.append(label)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing pair: {img1_path}, {img2_path}: {e}\")\n",
    "    return embeddings, labels\n",
    "\n",
    "# Generate embeddings for training and testing pairs\n",
    "train_embeddings, train_labels = generate_embeddings(train_pairs, embedding_model, augment=True)\n",
    "test_embeddings, test_labels = generate_embeddings(test_pairs, embedding_model, augment=False)\n",
    "\n",
    "# Normalize embeddings\n",
    "train_embeddings = [(normalize([emb1])[0], normalize([emb2])[0]) for emb1, emb2 in train_embeddings]\n",
    "test_embeddings = [(normalize([emb1])[0], normalize([emb2])[0]) for emb1, emb2 in test_embeddings]\n",
    "\n",
    "# Compute cosine similarity and optimize threshold\n",
    "def find_best_threshold(embeddings, labels):\n",
    "    similarities = [cosine_similarity([emb1], [emb2])[0][0] for emb1, emb2 in embeddings]\n",
    "    best_acc, best_threshold = 0, 0.5\n",
    "    for threshold in np.arange(0.1, 0.9, 0.01):\n",
    "        predictions = [1 if sim > threshold else 0 for sim in similarities]\n",
    "        acc = np.mean(np.array(predictions) == np.array(labels))\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_threshold = threshold\n",
    "    return best_threshold, best_acc\n",
    "\n",
    "# Evaluate on training and testing pairs\n",
    "train_threshold, train_accuracy = find_best_threshold(train_embeddings, train_labels)\n",
    "test_threshold, test_accuracy = find_best_threshold(test_embeddings, test_labels)\n",
    "\n",
    "print(f\"Train Accuracy: {train_accuracy * 100:.2f}% with Threshold: {train_threshold}\")\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}% with Threshold: {test_threshold}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
